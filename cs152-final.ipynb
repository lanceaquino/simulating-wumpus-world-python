{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS152 Final \n",
    "\n",
    "## A Simplified Wumpus World Simulation in Python \n",
    "\n",
    "For this project, I aim to simulate the wumpus world where I design an agent to independently navigate the world. For this wumpus there are a few simplifications that were applied. Instead of finding its way back home, the win condition is the agent finding the gold. \n",
    "\n",
    "The worlds are designed such that there are no overlaps between wumpuses, pits and gold. The arrow mechanism is also ignored in this world. To start off, we implemented helper functions. We added a Literal class for representation in the KB and wumpus world. It seems cleaner since strings are messier to deal with. The other functions are for finding valud moves, visited cells, and path finding. \n",
    "\n",
    "For the path finding, I'm implementing a depth-first search. This is important to simulate the navigation of the agent from its current location to the target location. The dfs function returns a set of paths that the agent will be going through to reach the target location. Depth-first search is used as it simulates the agent's style of navigation which is going deeper into a cell that we have visited instead of checking each neighboring valid and visited cell (this is breadth-first which is not ideal for path finding) \n",
    "\n",
    "Next, the KB is designed in such a way that the agent will rule out multiple cells to be visited, safe and risky. More on this will be discussed later.\n",
    "\n",
    "All in all, the agent will be navigating its own in this Wumpus world and its objective is to keep playing till they die or find the gold. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up helping functions and classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Literal:\n",
    "    \"\"\"\n",
    "    This class assigns a variable to be a literal \n",
    "    We use this for representative purposes in the KB \n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.sign = True \n",
    "    \n",
    "    def __neg__(self): \n",
    "        new_literal = Literal(self.name)\n",
    "        new_literal.sign = not self.sign\n",
    "        return new_literal \n",
    "        \n",
    "    def __eq__(self, other): \n",
    "        return self.name == other.name\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.sign == True:\n",
    "            return self.name\n",
    "        else:\n",
    "            return \"~\"+self.name\n",
    "\n",
    "        \n",
    "def find_neighbors(cur_loc):\n",
    "    \"\"\"\n",
    "    This function helps find the adjacent cells \n",
    "    \"\"\"\n",
    "    neighbors = []\n",
    "\n",
    "    neighbors.append([cur_loc[0] + 1,cur_loc[1]]) # up\n",
    "    neighbors.append([cur_loc[0] - 1,cur_loc[1]]) # down \n",
    "    neighbors.append([cur_loc[0],cur_loc[1] + 1]) # right\n",
    "    neighbors.append([cur_loc[0],cur_loc[1] - 1]) # left\n",
    "    \n",
    "    return neighbors\n",
    "\n",
    "def valid_cells(cells):\n",
    "    \"\"\"\n",
    "    This function rules out cells that are outside the wumpus world \n",
    "    \"\"\"\n",
    "    valid = [] \n",
    "    for i,cell in enumerate(cells): \n",
    "        if (cell[0] >= 0 and cell[0] < 4) and (cell[1] >= 0 and cell[1] < 4):\n",
    "            valid.append(cell)\n",
    "            \n",
    "    return valid\n",
    "\n",
    "def unvisited_cells(cells, visited_cells, safe_cells):\n",
    "    \"\"\"\n",
    "    This function returns cells that have not been visited. \n",
    "    This is used for the KB (check updateKB method in Agent class)\n",
    "    \"\"\"\n",
    "    unvisited = [] \n",
    "    \n",
    "    for i, cell in enumerate(cells): \n",
    "        if cell not in visited_cells and cell not in safe_cells:\n",
    "            unvisited.append(cell)\n",
    "            \n",
    "    return unvisited \n",
    "            \n",
    "def dfs_find_path(cur_loc, target_loc, visited_cells):\n",
    "    \"\"\"\n",
    "    We need the visited and safe cells as part of our filtering in \n",
    "    possible node expansion. Here we use breadth-first search to help our agent \n",
    "    find a path towards the target location. \n",
    "    \"\"\"\n",
    "\n",
    "    visited = [cur_loc] # this is for visited in bfs tree \n",
    "    queue = [cur_loc] \n",
    "    \n",
    "    while queue:\n",
    "        # we take the recently acquired children to implement depth-first\n",
    "        s = queue.pop()\n",
    "        curr = s\n",
    "        # visited.append(s) # add expanded cell in visited\n",
    "        \n",
    "        if curr == target_loc:\n",
    "            visited.pop()\n",
    "            break\n",
    "\n",
    "        children = find_neighbors(curr) # find adj cells \n",
    "        children = valid_cells(children) #filter out invalid cells \n",
    "        n_iter = len(children)\n",
    "        for i in range(n_iter):\n",
    "            child = children[i]\n",
    "            \n",
    "            # as we navigate, we only consider the ones we haven't \n",
    "            # visited and the valid cells that have been visited by\n",
    "            # the agent before. We cannot explore cells that we \n",
    "            # have never been in \n",
    "            if (child not in visited) and (child in visited_cells):\n",
    "                queue.append(child)\n",
    "                visited.append(child)   \n",
    "\n",
    "    reversed_list = [elem[::-1] for elem in visited]\n",
    "                  \n",
    "    return reversed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up our literals to be used for representation \n",
    "G = Literal(\"G\") # Gold \n",
    "W = Literal(\"W\") # Wumpus \n",
    "pW = Literal(\"pW\") # potential Wumpus \n",
    "P = Literal(\"P\") # Pit \n",
    "pP = Literal(\"pP\") # potential Pit \n",
    "s = Literal(\"s\") # stench \n",
    "b = Literal(\"b\") # breeze \n",
    "OK = Literal(\"OK\") # OKAY = Safe cell \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing our Agent\n",
    "\n",
    "Our agent class mainly contains two methods which are updating its current KB and choosing its next move. It is best to this as the internal processes of the agent (what is happening in their mind?). We initialize with an empty KB and our indicators that the agent is alive and has gold. We always start at [0,0]. Lastly, we also keep track of the cells that we have visited, find safe and risky. \n",
    "\n",
    "The update KB follows a basic format of observing its perceptions in the current cells and making assumptions at the adjacent cells. It follows the following logical equations:\n",
    "\n",
    "let $i,j$ be the current location \n",
    "\n",
    "let the following literals be defined: \n",
    "- $P : Pit$\n",
    "- $B : Breeze$\n",
    "- $S : Stench$\n",
    "- $W : Wumpus$\n",
    "- $OK : Safe$\n",
    "\n",
    "let the following be the rules the KB has to follow:\n",
    "- $B_{i,j} \\rightarrow P_{i-1,j} \\lor P_{i+1, j} \\lor P_{i, j -1} \\lor P_{i,j+1}$\n",
    "- $S_{i,j} \\rightarrow W_{i-1,j} \\lor W_{i+1, j} \\lor W_{i, j -1} \\lor W_{i,j+1}$\n",
    "- $\\text{No percept}_{i,j} \\rightarrow OK_{i-1,j} \\lor OK_{i+1, j} \\lor OK_{i, j -1} \\lor OK_{i,j+1}$\n",
    "\n",
    "Every time an agent goes to a new cell, it will send the respective assumptions in the valid neighboring cells at the same time checking if the cell has been visited or rules as safe. If so, then there will be no assumptions added to this cell. Basically, it will only add these assumptions on unvisited adjacent cells and add these cells to the risky cells list. \n",
    "\n",
    "This is a very simplified version of the proper rules of the Wumpus world and it does have its limitations. More on this in the discussion later. \n",
    "\n",
    "The purpose of our KB is to continously update the safe and risky cells as we move along the map. The agent's way of moving around is to always prioritize safe cells. These are cells that are observed to have no wumpuses or breezes. This can be from a neighboring empty cell or a risky cell that was randomly chosen and the agent finds that there are no percepts in this current cell. In case the agent runs out of safe cells to explore, it will then take a risk by randomly choosing between the risky cells and take a leap of faith. These risky cells are presumed to have a pit or a wumpus. If the agent stumbles upon these two, then it will die. If not, then the agent is lucky and will rule the current cell as safe and visited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # setting up our knowledge base \n",
    "        # our default we already have assumptions \n",
    "        self.KB = [\n",
    "            [[OK],[],[],[]],\n",
    "            [[],[],[],[]],\n",
    "            [[],[],[],[]],\n",
    "            [[],[],[],[]]]    \n",
    "        \n",
    "        self.is_Alive = True  \n",
    "        self.has_Gold = False \n",
    "                \n",
    "        # Default starting location of our agent \n",
    "        self.cur_loc = [0,0]\n",
    "        \n",
    "        # Keep track of the cells we encounter and inferred \n",
    "        self.visited_cells = [self.cur_loc] # visited cells are already known as safe \n",
    "        self.safe_cells = []\n",
    "        self.risky_cells = [] \n",
    "        \n",
    "    def KBshow(self, loc):\n",
    "        return self.KB[loc[0]][loc[1]]\n",
    "    \n",
    "    def Worldshow(self):\n",
    "        KB_copy = copy.deepcopy(self.KB)\n",
    "        \n",
    "        KB_copy[self.cur_loc[0]][self.cur_loc[1]].append(\"A\")\n",
    "        \n",
    "        return KB_copy\n",
    "    \n",
    "    def update_KB(self, loc, wumpus_world):\n",
    "        \"\"\"\n",
    "        This method will be updating the KB based \n",
    "        on its newly acquired perceptions\n",
    "        \"\"\"\n",
    "        \n",
    "        adj = find_neighbors(loc)\n",
    "        adj = valid_cells(adj)\n",
    "        \n",
    "        # what the agent finds in its current location \n",
    "        percept = wumpus_world.show(loc)\n",
    "\n",
    "        # add assumptions based on acquired percepts \n",
    "        if percept == []: # no observations, adj cells are safe \n",
    "            del self.KBshow(loc)[:]\n",
    "            self.KBshow(loc).append(OK)\n",
    "            \n",
    "            # Remove current cell from risky cells \n",
    "            if loc in self.risky_cells:\n",
    "                for i, cell in enumerate(self.risky_cells):\n",
    "                    if loc == cell:\n",
    "                        self.risky_cells.pop(i)\n",
    "                        \n",
    "            # Update surroundings of 0 percept cell \n",
    "            for cell in adj:\n",
    "                if OK not in self.KBshow(cell):\n",
    "                    self.KBshow(cell).append(OK)\n",
    "                if cell not in self.safe_cells:\n",
    "                    self.safe_cells.append(cell)\n",
    "                \n",
    "        else:       \n",
    "            # we don't add assumptions for visited and safe cells \n",
    "            valid_unvisited = unvisited_cells(adj, self.visited_cells, self.safe_cells) \n",
    "            \n",
    "            # add our assumptions to adjacent cells \n",
    "            for p in percept:\n",
    "                if p == G:\n",
    "                    self.has_Gold = True \n",
    "                    \n",
    "                if p == W or p == P:\n",
    "                    self.is_Alive = False \n",
    "                \n",
    "                if p == s: \n",
    "                    self.KBshow(loc).append(s)\n",
    "                    for cell in valid_unvisited:\n",
    "                        if pW not in self.KBshow(cell):\n",
    "                            self.KBshow(cell).append(pW)\n",
    "                        if cell not in self.risky_cells:\n",
    "                            self.risky_cells.append(cell)\n",
    "                        \n",
    "                elif p == b: \n",
    "                    self.KBshow(loc).append(b)\n",
    "                    for cell in valid_unvisited:\n",
    "                        if pP not in self.KBshow(cell):\n",
    "                            self.KBshow(cell).append(pP)\n",
    "                        if cell not in self.risky_cells:\n",
    "                            self.risky_cells.append(cell)\n",
    "    \n",
    "    def get_next_move(self):\n",
    "        \"\"\"\n",
    "        This method will make the agent choose \n",
    "        the next move based on its collected list of cells and risky cells \n",
    "        The idea is to always search around the safe cells and if we cannot \n",
    "        find any, we take our chances with the risky cells. \n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.safe_cells) > 0: \n",
    "            return self.safe_cells.pop(0)\n",
    "        \n",
    "        else: \n",
    "            if len(self.risky_cells) > 1:\n",
    "                return self.risky_cells.pop(np.random.randint(0, len(self.risky_cells) - 1))\n",
    "            else:\n",
    "                return self.risky_cells.pop()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the simulation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_simulate_Wumpus(agent, world):\n",
    "    \"\"\"\n",
    "    This function will be implementing the simulation of the wumpus world \n",
    "    \"\"\"\n",
    "    \n",
    "    # metrics \n",
    "    visited_cells = [] \n",
    "    \n",
    "    \n",
    "    # Initialize our agent and world     \n",
    "    ag = agent \n",
    "    wump_world = world \n",
    "    ag.update_KB(ag.cur_loc, wump_world)\n",
    "    print(\"WUMPUS WORLD\")\n",
    "    for i in wump_world.world:\n",
    "        print(i)\n",
    "    steps = 0\n",
    "    while ag.is_Alive and not ag.has_Gold:\n",
    "        next_loc = ag.get_next_move() \n",
    "        ag.visited_cells.append(next_loc)\n",
    "        \n",
    "        # Acquire our agent's path \n",
    "        print(f\"---------- ITER: {steps} ----------\")\n",
    "\n",
    "        path = dfs_find_path(ag.cur_loc, next_loc, ag.visited_cells)\n",
    "        \n",
    "        for cell in path:\n",
    "            visited_cells.append(cell)\n",
    "\n",
    "        ag.cur_loc = next_loc \n",
    "        \n",
    "        ag.update_KB(ag.cur_loc, wump_world)\n",
    "        print(f\"Curr perception: {wump_world.show(ag.cur_loc)} at position {ag.cur_loc}\")\n",
    "\n",
    "        print(\"VISITED CELLS\", ag.visited_cells)\n",
    "        print(\"SAFE CELLS\", ag.safe_cells)\n",
    "        print(\"RISKY CELLS\", ag.risky_cells)\n",
    "        \n",
    "        print(\"ALIVE:\", ag.is_Alive)\n",
    "        print(\"HAS GOLD:\", ag.has_Gold)\n",
    "        print(\"---\")\n",
    "        print(\"KB and Agent position:\", ag.cur_loc)\n",
    "        for i in ag.Worldshow():\n",
    "            print(i)\n",
    "            \n",
    "        steps += 1\n",
    "    print(\"-----END SCORE -----\")\n",
    "    \n",
    "    # Agent died \n",
    "    if ag.is_Alive == False and ag.has_Gold == False:\n",
    "        win = 0 \n",
    "        print(\"AGENT LOST \")\n",
    "    \n",
    "    # Agent got the gold and surived \n",
    "    if ag.is_Alive == True and ag.has_Gold == True:\n",
    "        win = 1 \n",
    "        print(\"AGENT WON\")\n",
    "        \n",
    "    print(\"Steps taken:\", len(visited_cells))\n",
    "    \n",
    "    visited_cells.append(ag.cur_loc)\n",
    "    \n",
    "    print(\"Path: \", visited_cells)\n",
    "    return visited_cells, steps, win "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of a few steps of our agent \n",
    "\n",
    "Here is a tractable progression of the agent as it navigates the wumpus world. The world is set to easy so we can see that the agent actually wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WUMPUS WORLD\n",
      "[[], [], [], []]\n",
      "[[s], [G, b], [], []]\n",
      "[[W, b], [P, s], [], []]\n",
      "[[s], [b], [], []]\n",
      "---------- ITER: 0 ----------\n",
      "Curr perception: [s] at position [1, 0]\n",
      "VISITED CELLS [[0, 0], [1, 0]]\n",
      "SAFE CELLS [[0, 1]]\n",
      "RISKY CELLS [[2, 0], [1, 1]]\n",
      "ALIVE: True\n",
      "HAS GOLD: False\n",
      "---\n",
      "KB and Agent position: [1, 0]\n",
      "[[OK], [OK], [], []]\n",
      "[[OK, s, 'A'], [pW], [], []]\n",
      "[[pW], [], [], []]\n",
      "[[], [], [], []]\n",
      "---------- ITER: 1 ----------\n",
      "Curr perception: [] at position [0, 1]\n",
      "VISITED CELLS [[0, 0], [1, 0], [0, 1]]\n",
      "SAFE CELLS [[1, 1], [0, 2], [0, 0]]\n",
      "RISKY CELLS [[2, 0], [1, 1]]\n",
      "ALIVE: True\n",
      "HAS GOLD: False\n",
      "---\n",
      "KB and Agent position: [0, 1]\n",
      "[[OK], [OK, 'A'], [OK], []]\n",
      "[[OK, s], [pW, OK], [], []]\n",
      "[[pW], [], [], []]\n",
      "[[], [], [], []]\n",
      "---------- ITER: 2 ----------\n",
      "Curr perception: [G, b] at position [1, 1]\n",
      "VISITED CELLS [[0, 0], [1, 0], [0, 1], [1, 1]]\n",
      "SAFE CELLS [[0, 2], [0, 0]]\n",
      "RISKY CELLS [[2, 0], [1, 1], [2, 1], [1, 2]]\n",
      "ALIVE: True\n",
      "HAS GOLD: True\n",
      "---\n",
      "KB and Agent position: [1, 1]\n",
      "[[OK], [OK], [OK], []]\n",
      "[[OK, s], [pW, OK, b, 'A'], [pP], []]\n",
      "[[pW], [pP], [], []]\n",
      "[[], [], [], []]\n",
      "-----END SCORE -----\n",
      "AGENT WON\n",
      "Steps taken: 6\n",
      "Path:  [[0, 0], [0, 1], [0, 0], [1, 0], [1, 1], [0, 0], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "world = [\n",
    "    [[],[b],[P],[b]],\n",
    "    [[s],[],[b],[]],\n",
    "    [[W],[s],[],[]],\n",
    "    [[s],[],[G],[]]\n",
    "]\n",
    "\n",
    "easy_world = [\n",
    "    [[],[],[],[]],\n",
    "    [[s],[G, b],[],[]],\n",
    "    [[W, b],[P, s],[],[]],\n",
    "    [[s],[b],[],[]]\n",
    "]\n",
    "\n",
    "ag = Agent()\n",
    "wump_world = WumpusWorld(easy_world)\n",
    "\n",
    "_,_,_ = sample_simulate_Wumpus(ag, wump_world)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Simulations and Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_Wumpus(agent, world):\n",
    "    \"\"\"\n",
    "    This function will be implementing the simulation of the wumpus world \n",
    "    \"\"\"\n",
    "    \n",
    "    # metrics \n",
    "    visited_cells = [] \n",
    "    win = None\n",
    "    steps = 0\n",
    "    \n",
    "    # Initialize our agent and world     \n",
    "    ag = agent \n",
    "    wump_world = world \n",
    "    ag.update_KB(ag.cur_loc, wump_world)\n",
    "\n",
    "    while ag.is_Alive and not ag.has_Gold:\n",
    "        next_loc = ag.get_next_move() \n",
    "        ag.visited_cells.append(next_loc)\n",
    "        \n",
    "        # Acquire our agent's path \n",
    "        path = dfs_find_path(ag.cur_loc, next_loc, ag.visited_cells)\n",
    "        \n",
    "        for cell in path:\n",
    "            visited_cells.append(cell)\n",
    "\n",
    "        ag.cur_loc = next_loc \n",
    "        \n",
    "        ag.update_KB(ag.cur_loc, wump_world)\n",
    "\n",
    "            \n",
    "        steps += 1\n",
    "    \n",
    "    # Agent died \n",
    "    if ag.is_Alive == False and ag.has_Gold == False:\n",
    "        win = 0 \n",
    "    \n",
    "    # Agent got the gold and surived \n",
    "    if ag.is_Alive == True and ag.has_Gold == True:\n",
    "        win = 1 \n",
    "        \n",
    "    \n",
    "    return visited_cells, steps, win "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "world = [\n",
    "    [[],[b],[P],[b]],\n",
    "    [[s],[],[b],[]],\n",
    "    [[W],[s],[],[]],\n",
    "    [[s],[],[G],[]]\n",
    "]\n",
    "\n",
    "easy_world = [\n",
    "    [[],[],[],[]],\n",
    "    [[s],[G, b],[],[]],\n",
    "    [[W, b],[P, s],[],[]],\n",
    "    [[s],[b],[],[]]\n",
    "]\n",
    "\n",
    "hard_world = [\n",
    "    [[b],[P],[b],[G]],\n",
    "    [[b],[P],[b],[G]],\n",
    "    [[s],[W],[s],[G]],\n",
    "    [[G],[G,s],[G],[G]]\n",
    "]\n",
    "\n",
    "\n",
    "def mult_sims(world, n_steps):\n",
    "    wins = []\n",
    "    steps_taken = []\n",
    "    for i in range(n_steps): \n",
    "        ag = Agent()\n",
    "        wump_world = WumpusWorld(world)\n",
    "\n",
    "        visited_cells, _, win = simulate_Wumpus(ag, wump_world)\n",
    "\n",
    "        wins.append(win)\n",
    "\n",
    "        if win ==1:\n",
    "            steps_taken.append(len(visited_cells))\n",
    "            \n",
    "    \n",
    "    return wins, steps_taken \n",
    "\n",
    "n_steps = 10000\n",
    "\n",
    "# normal\n",
    "normal = mult_sims(world, n_steps)\n",
    "\n",
    "# easy \n",
    "easy = mult_sims(easy_world, n_steps)\n",
    "\n",
    "# hard \n",
    "hard = mult_sims(hard_world, n_steps)\n",
    "\n",
    "fig, ax = plt.subplots(1,3 , figsize = [20,5])\n",
    "\n",
    "for i in range(3):\n",
    "    ax[0].set_title(f\"Easy mode num cells visited win prob: {sum(easy[0])/n_steps}\")\n",
    "    ax[0].hist(easy[1])\n",
    "    \n",
    "    ax[1].set_title(f\"Normal mode num cells visited win prob: {sum(normal[0])/n_steps}\")\n",
    "    ax[1].hist(normal[1])\n",
    "    \n",
    "    ax[2].set_title(f\"Hard mode num cells visited win prob: {sum(hard[0])/n_steps}\")\n",
    "    ax[2].hist(hard[1])\n",
    "    \n",
    "    ax[i].set_xlabel(\"Number of cells visited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "Our results show what is expected. Easy mode would result in 100% win rate because the G is part of the safe cells and the agent will always look into the safe cells. As for the normal mode, there is a slight different in the number of cells visited to actually win. Also, the agent only wins 1 out of 4 games. This is because the set-up of the medium world is that the agent will always have to choos between risky cells where they have 1 out of 4 chances of getting the safe cell. The hard mode shows the lowest win rate which is 15% and this is because the agent will have to take risky decisions all the time and all the cells visited are not safe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Improvements \n",
    "\n",
    "This simulation of the wumpus world was simplified especially in the KB processing. It does not implement all the logical rules that can be derived from the wumpus world. We can further improve the KB by adding a process as to which we can rule out the wumpus. Since there is only one wumpus, if we find a cell that has two neighboring stench cells (assuming that we are following a von Neummann neighborhood system), then we can say that that specific cell has a wumpus. We can also improve the mode of choosing between risky cells. We can never avoid an empty safe cell and there will come a time we need to take a chance. We can implement probability theory in choosing the risky cells. An example would be to apply the perceptions of the cell and its neighboring cells and determine the probability of the cell having a wumpus or a pit. We then program the agent to choose the risky cell that has the least amount of risk. Probability-wise, this should increase our chances of winning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
